#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Flask API –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω—É ‚Ññ168-–§–ó
–£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
"""

from flask import Flask, render_template, request, jsonify, send_file, session
from flask_cors import CORS
import os
from datetime import datetime
from checker import RussianLanguageChecker
import requests
from bs4 import BeautifulSoup
import io
import json
import uuid
from collections import defaultdict

app = Flask(__name__)
# CORS - —Ä–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ –¥–æ–º–µ–Ω—ã
CORS(app, resources={
    r"/api/*": {
        "origins": "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–µ–∫–µ—Ä–∞
checker = RussianLanguageChecker()

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ–≤–µ—Ä–æ–∫ (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Redis/Database)
check_history = []
statistics = {
    'total_checks': 0,
    'total_violations': 0,
    'most_common_violations': defaultdict(int)
}

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/about')
def about():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ –∑–∞–∫–æ–Ω–µ"""
    return render_template('about.html')

@app.route('/api-docs')
def api_docs():
    """API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"""
    return render_template('api_docs.html')

@app.route('/examples')
def examples():
    """–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    return render_template('examples.html')
    
@app.route('/robots.txt')
def robots():
    """Robots.txt"""
    return send_file('static/robots.txt', mimetype='text/plain')

@app.route('/favicon.ico')
def favicon():
    """Favicon"""
    return '', 204  # No content - –∏—Å–ø–æ–ª—å–∑—É–µ–º data URI –≤ HTML

# ==================== API ENDPOINTS ====================

@app.route('/api/check', methods=['POST'])
def check_text():
    """API: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    try:
        data = request.json
        text = data.get('text', '')
        save_history = data.get('save_history', True)
        
        if not text or not text.strip():
            return jsonify({'error': '–¢–µ–∫—Å—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'}), 400
        
        result = checker.check_text(text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        result['recommendations'] = generate_recommendations(result)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        if save_history:
            save_to_history('text', result, text[:100])
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        update_statistics(result)
        
        return jsonify({
            'success': True,
            'result': result,
            'timestamp': datetime.now().isoformat(),
            'check_id': str(uuid.uuid4())
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/check-url', methods=['POST'])
def check_url():
    """API: –ü—Ä–æ–≤–µ—Ä–∫–∞ URL"""
    try:
        data = request.json
        url = data.get('url', '')
        
        if not url or not url.startswith('http'):
            return jsonify({'error': '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL'}), 400
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        response = requests.get(url, timeout=15, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω–æ–µ
        for tag in soup(['script', 'style', 'nav', 'footer', 'header']):
            tag.decompose()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        text = soup.get_text(separator=' ', strip=True)
        title = soup.find('title')
        title_text = title.get_text() if title else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
        
        result = checker.check_text(text)
        result['page_title'] = title_text
        result['recommendations'] = generate_recommendations(result)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        save_to_history('url', result, url)
        update_statistics(result)
        
        return jsonify({
            'success': True,
            'url': url,
            'result': result,
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}'}), 500

@app.route('/api/batch-check', methods=['POST'])
def batch_check():
    """API: –ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"""
    try:
        data = request.json
        urls = data.get('urls', [])
        
        if not urls:
            return jsonify({'error': '–°–ø–∏—Å–æ–∫ URL –ø—É—Å—Ç'}), 400
        
        results = []
        for url in urls[:50]:  # –õ–∏–º–∏—Ç 50 URL –∑–∞ —Ä–∞–∑
            try:
                response = requests.get(url, timeout=10, headers={
                    'User-Agent': 'Mozilla/5.0'
                })
                soup = BeautifulSoup(response.text, 'html.parser')
                for tag in soup(['script', 'style']):
                    tag.decompose()
                text = soup.get_text(separator=' ', strip=True)
                result = checker.check_text(text)
                
                results.append({
                    'url': url,
                    'success': True,
                    'result': result
                })
                
            except Exception as e:
                results.append({
                    'url': url,
                    'success': False,
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'total': len(urls),
            'results': results,
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """API: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π"""
    try:
        stats_data = {
            'normative': len(checker.normative_words),
            'foreign': len(checker.foreign_allowed),
            'nenormative': len(checker.nenormative_words),
            'morph_available': checker.morph is not None
        }
        
        print(f"üìä –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {stats_data}")  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        
        return jsonify(stats_data)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ /api/stats: {e}")
        return jsonify({
            'normative': 0,
            'foreign': 0,
            'nenormative': 0,
            'morph_available': False,
            'error': str(e)
        }), 500

@app.route('/api/history', methods=['GET'])
def get_history():
    """API: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫"""
    limit = int(request.args.get('limit', 10))
    return jsonify({
        'history': check_history[-limit:][::-1],
        'total': len(check_history)
    })

@app.route('/api/export/txt', methods=['POST'])
def export_txt():
    """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ TXT —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π"""
    try:
        data = request.get_json()
        result = data.get('result', {})
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        lines = []
        lines.append("=" * 70)
        lines.append("–û–¢–ß–ï–¢ –ü–†–û–í–ï–†–ö–ò –¢–ï–ö–°–¢–ê –ù–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –§–ó-168")
        lines.append("=" * 70)
        lines.append(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
        lines.append(f"ID –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(uuid.uuid4())[:8]}")
        lines.append("")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("-" * 70)
        lines.append("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        lines.append("-" * 70)
        lines.append(f"  –í—Å–µ–≥–æ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ:     {result.get('total_words', 0)}")
        lines.append(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤:         {result.get('unique_words', 0)}")
        lines.append(f"  –ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ:       {result.get('violations_count', 0)}")
        lines.append("")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        lines.append("-" * 70)
        lines.append("–î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        lines.append("-" * 70)
        lines.append(f"  ‚úÖ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞:   {result.get('normative_count', result.get('total_words', 0) - result.get('violations_count', 0))}")
        lines.append(f"  üåç –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞:   {result.get('foreign_count', result.get('latin_count', 0))}")
        lines.append(f"  üö´ –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞: {result.get('nenormative_count', 0)}")
        lines.append(f"  ‚úèÔ∏è –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ:      {result.get('orfograf_count', 0)}")
        lines.append(f"  üîä –û—Ä—Ñ–æ—ç–ø–∏—á–µ—Å–∫–∏–µ:        {result.get('orfoep_count', 0)}")
        lines.append(f"  ‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞:    {result.get('unknown_count', 0)}")
        lines.append("")
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        compliance = result.get('compliance_percentage', 0)
        if result.get('law_compliant', result.get('violations_count', 0) == 0):
            compliance = 100.0
            status = "‚úÖ –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢"
        else:
            total = result.get('total_words', 1)
            violations = result.get('violations_count', 0)
            compliance = ((total - violations) / total) * 100 if total > 0 else 0
            status = "‚ùå –ù–ï –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢"
        
        lines.append("-" * 70)
        lines.append(f"–°–¢–ê–¢–£–°: {status}")
        lines.append(f"–ü–†–û–¶–ï–ù–¢ –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø: {compliance:.2f}%")
        lines.append("-" * 70)
        lines.append("")
        
        # –ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
        has_violations = False
        
        # –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞
        nenormative_words = result.get('nenormative_words', [])
        if nenormative_words:
            has_violations = True
            lines.append("=" * 70)
            lines.append(f"üö´ –ù–ï–ù–û–†–ú–ê–¢–ò–í–ù–ê–Ø –õ–ï–ö–°–ò–ö–ê ({len(nenormative_words)} —Å–ª–æ–≤):")
            lines.append("=" * 70)
            for i, word in enumerate(nenormative_words, 1):
                lines.append(f"  {i:3d}. {word}")
            lines.append("")
        
        # –°–ª–æ–≤–∞ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ
        latin_words = result.get('latin_words', [])
        if latin_words:
            has_violations = True
            lines.append("=" * 70)
            lines.append(f"üåç –ò–ù–û–°–¢–†–ê–ù–ù–´–ï –°–õ–û–í–ê –ù–ê –õ–ê–¢–ò–ù–ò–¶–ï ({len(latin_words)} —Å–ª–æ–≤):")
            lines.append("=" * 70)
            for i, word in enumerate(latin_words, 1):
                lines.append(f"  {i:3d}. {word}")
            lines.append("")
        
        # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ/–∞–Ω–≥–ª–∏—Ü–∏–∑–º—ã
        unknown_cyrillic = result.get('unknown_cyrillic', [])
        if unknown_cyrillic:
            has_violations = True
            lines.append("=" * 70)
            lines.append(f"‚ùì –ê–ù–ì–õ–ò–¶–ò–ó–ú–´ / –ù–ï–ò–ó–í–ï–°–¢–ù–´–ï –°–õ–û–í–ê ({len(unknown_cyrillic)} —Å–ª–æ–≤):")
            lines.append("=" * 70)
            for i, word in enumerate(unknown_cyrillic, 1):
                lines.append(f"  {i:3d}. {word}")
            lines.append("")
        
        # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        orfograf_words = result.get('orfograf_words', [])
        if orfograf_words:
            has_violations = True
            lines.append("=" * 70)
            lines.append(f"‚úèÔ∏è –û–†–§–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò ({len(orfograf_words)} —Å–ª–æ–≤):")
            lines.append("=" * 70)
            for i, word in enumerate(orfograf_words, 1):
                lines.append(f"  {i:3d}. {word}")
            lines.append("")
        
        # –û—Ä—Ñ–æ—ç–ø–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        orfoep_words = result.get('orfoep_words', [])
        if orfoep_words:
            has_violations = True
            lines.append("=" * 70)
            lines.append(f"üîä –û–†–§–û–≠–ü–ò–ß–ï–°–ö–ò–ï –û–®–ò–ë–ö–ò ({len(orfoep_words)} —Å–ª–æ–≤):")
            lines.append("=" * 70)
            for i, word in enumerate(orfoep_words, 1):
                lines.append(f"  {i:3d}. {word}")
            lines.append("")
        
        if not has_violations:
            lines.append("=" * 70)
            lines.append("‚úÖ –ù–ê–†–£–®–ï–ù–ò–ô –ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù–û")
            lines.append("=" * 70)
            lines.append("")
            lines.append("–¢–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –∑–∞–∫–æ–Ω–∞ –æ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.")
            lines.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = result.get('recommendations', [])
        if recommendations:
            lines.append("=" * 70)
            lines.append("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            lines.append("=" * 70)
            for rec in recommendations:
                level = rec.get('level', 'info')
                icon = 'üî¥' if level == 'critical' else 'üü°' if level == 'warning' else 'üü¢' if level == 'success' else '‚ÑπÔ∏è'
                lines.append(f"{icon} {rec.get('title', '')}")
                lines.append(f"   {rec.get('message', '')}")
                if rec.get('action'):
                    lines.append(f"   ‚Üí –î–µ–π—Å—Ç–≤–∏–µ: {rec['action']}")
                lines.append("")
        
        # –ü–æ–¥–≤–∞–ª
        lines.append("=" * 70)
        lines.append("–°–æ–∑–¥–∞–Ω–æ: LawChecker Online")
        lines.append("–°–∞–π—Ç: https://lawcheck-production.up.railway.app")
        lines.append("–ó–∞–∫–æ–Ω: –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω ‚Ññ168-–§–ó ¬´–û —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ¬ª")
        lines.append("=" * 70)
        
        report = "\n".join(lines)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å BOM –¥–ª—è Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        output = io.BytesIO()
        output.write('\ufeff'.encode('utf-8'))  # UTF-8 BOM
        output.write(report.encode('utf-8'))
        output.seek(0)
        
        return send_file(
            output,
            mimetype='text/plain; charset=utf-8',
            as_attachment=True,
            download_name=f'lawcheck_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export/json', methods=['POST'])
def export_json():
    """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –≤ JSON"""
    try:
        data = request.get_json()
        result = data.get('result', {})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result['exported_at'] = datetime.now().isoformat()
        result['tool'] = 'LawChecker Online'
        
        output = io.BytesIO()
        output.write(json.dumps(result, ensure_ascii=False, indent=2).encode('utf-8'))
        output.seek(0)
        
        return send_file(
            output,
            mimetype='application/json',
            as_attachment=True,
            download_name=f'lawcheck_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================

def save_to_history(check_type, result, context):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    check_history.append({
        'id': str(uuid.uuid4()),
        'type': check_type,
        'timestamp': datetime.now().isoformat(),
        'violations': result['violations_count'],
        'compliant': result['law_compliant'],
        'context': context
    })
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
    if len(check_history) > 1000:
        check_history.pop(0)

def update_statistics(result):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    statistics['total_checks'] += 1
    statistics['total_violations'] += result['violations_count']
    
    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π
    for word in result.get('latin_words', [])[:10]:
        statistics['most_common_violations'][word] += 1
    for word in result.get('unknown_cyrillic', [])[:10]:
        statistics['most_common_violations'][word] += 1

def generate_recommendations(result):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é"""
    recommendations = []
    
    if result.get('nenormative_count', 0) > 0:
        recommendations.append({
            'level': 'critical',
            'icon': 'üö´',
            'title': '–ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞',
            'message': f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {result['nenormative_count']} —Å–ª–æ–≤ –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏. –≠—Ç–æ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∑–∞–∫–æ–Ω–∞.",
            'action': '–ó–∞–º–µ–Ω–∏—Ç–µ –∏–ª–∏ —É–¥–∞–ª–∏—Ç–µ –≤—Å–µ –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.'
        })
    
    if result.get('latin_count', 0) > 0:
        recommendations.append({
            'level': 'warning',
            'icon': '‚ö†Ô∏è',
            'title': '–õ–∞—Ç–∏–Ω–∏—Ü–∞ –≤ —Ç–µ–∫—Å—Ç–µ',
            'message': f"–ù–∞–π–¥–µ–Ω–æ {result['latin_count']} —Å–ª–æ–≤ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ.",
            'action': '–ó–∞–º–µ–Ω–∏—Ç–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–µ –∞–Ω–∞–ª–æ–≥–∏ –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö.'
        })
    
    if result.get('unknown_count', 0) > 0:
        recommendations.append({
            'level': 'info',
            'icon': '‚ÑπÔ∏è',
            'title': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞',
            'message': f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {result['unknown_count']} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∞–Ω–≥–ª–∏—Ü–∏–∑–º–æ–≤ –∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤.",
            'action': '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—â–µ–ø—Ä–∏–Ω—è—Ç—ã–µ —Ç–µ—Ä–º–∏–Ω—ã.'
        })
    
    if result['law_compliant']:
        recommendations.append({
            'level': 'success',
            'icon': '‚úÖ',
            'title': '–¢–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–∫–æ–Ω—É',
            'message': '–ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. –¢–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –§–ó ‚Ññ168.',
            'action': '–ú–æ–∂–Ω–æ –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.'
        })
    
    return recommendations

def get_word_suggestions(word):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ –∑–∞–º–µ–Ω–µ —Å–ª–æ–≤–∞"""
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –ø–æ–¥–±–æ—Ä–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
    suggestions = []
    
    # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∑–∞–º–µ–Ω (—Ä–∞—Å—à–∏—Ä—å—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã)
    replacements = {
        'hello': '–ø—Ä–∏–≤–µ—Ç',
        'world': '–º–∏—Ä',
        'computer': '–∫–æ–º–ø—å—é—Ç–µ—Ä',
        'email': '—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞',
        'internet': '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç',
        'software': '–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ',
    }
    
    word_lower = word.lower()
    if word_lower in replacements:
        suggestions.append(replacements[word_lower])
    
    return suggestions if suggestions else ['–ù–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π']

def calculate_readability(text):
    """–†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
    words = text.split()
    sentences = [s for s in text.split('.') if s.strip()]
    
    if not words or not sentences:
        return 0
    
    avg_sentence_length = len(words) / len(sentences)
    avg_word_length = sum(len(w) for w in words) / len(words)
    
    # –ü—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
    readability = (avg_sentence_length * 0.5) + (avg_word_length * 2)
    
    return round(readability, 2)

def get_word_frequency(text):
    """–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤"""
    words = text.lower().split()
    frequency = defaultdict(int)
    
    for word in words:
        if len(word) > 3:
            frequency[word] += 1
    
    return dict(sorted(frequency.items(), key=lambda x: x[1], reverse=True)[:10])

def calculate_complexity(text):
    """–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ (0-100)"""
    words = text.split()
    
    if not words:
        return 0
    
    avg_word_length = sum(len(w) for w in words) / len(words)
    unique_words = len(set(words))
    lexical_diversity = unique_words / len(words)
    
    complexity = (avg_word_length * 10) + (lexical_diversity * 30)
    
    return min(100, round(complexity, 2))

def calculate_improvement(result1, result2):
    """–†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É–ª—É—á—à–µ–Ω–∏—è"""
    if result1['violations_count'] == 0:
        return 0
    
    improvement = ((result1['violations_count'] - result2['violations_count']) / result1['violations_count']) * 100
    return round(improvement, 2)

def generate_text_report(result):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    output = "="*100 + "\n"
    output += "–û–¢–ß–Å–¢ –ü–û –ü–†–û–í–ï–†–ö–ï –ó–ê–ö–û–ù–ê –û –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï ‚Ññ168-–§–ó\n"
    output += f"–°–æ–∑–¥–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    output += "="*100 + "\n\n"
    
    output += f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {result.get('total_words', 0)}\n"
    output += f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {result.get('unique_words', 0)}\n"
    output += f"–ù–∞—Ä—É—à–µ–Ω–∏–π: {result.get('violations_count', 0)}\n\n"
    
    if result.get('law_compliant'):
        output += "‚úÖ –¢–ï–ö–°–¢ –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢ –¢–†–ï–ë–û–í–ê–ù–ò–Ø–ú –ó–ê–ö–û–ù–ê\n\n"
    else:
        output += f"‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–û –ù–ê–†–£–®–ï–ù–ò–ô: {result.get('violations_count', 0)}\n\n"
        
        if result.get('nenormative_count', 0) > 0:
            output += f"üö´ –ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞: {result['nenormative_count']}\n"
        if result.get('latin_count', 0) > 0:
            output += f"‚ö†Ô∏è –õ–∞—Ç–∏–Ω–∏—Ü–∞: {result['latin_count']}\n"
            for i, word in enumerate(result.get('latin_words', [])[:50], 1):
                output += f"  {i}. {word}\n"
            output += "\n"
        if result.get('unknown_count', 0) > 0:
            output += f"‚ö†Ô∏è –ê–Ω–≥–ª–∏—Ü–∏–∑–º—ã: {result['unknown_count']}\n"
            for i, word in enumerate(result.get('unknown_cyrillic', [])[:50], 1):
                output += f"  {i}. {word}\n"
    
    return output

def generate_csv_report(result):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –æ—Ç—á–µ—Ç–∞"""
    output = "–¢–∏–ø,–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ,–°–ª–æ–≤–∞\n"
    
    output += f"–õ–∞—Ç–∏–Ω–∏—Ü–∞,{result.get('latin_count', 0)},\"{', '.join(result.get('latin_words', [])[:20])}\"\n"
    output += f"–ê–Ω–≥–ª–∏—Ü–∏–∑–º—ã,{result.get('unknown_count', 0)},\"{', '.join(result.get('unknown_cyrillic', [])[:20])}\"\n"
    output += f"–ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è,{result.get('nenormative_count', 0)},\"[—Å–∫—Ä—ã—Ç–æ]\"\n"
    
    return output

def generate_html_report(result):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞"""
    html = f"""
    <!DOCTYPE html>
    <html lang="ru">
    <head>
        <meta charset="UTF-8">
        <title>–û—Ç—á–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –§–ó ‚Ññ168</title>
        <style>
            body {{ font-family: Arial, sans-serif; max-width: 1000px; margin: 50px auto; padding: 20px; }}
            .header {{ background: #1976D2; color: white; padding: 20px; border-radius: 8px; }}
            .status {{ padding: 20px; margin: 20px 0; border-radius: 8px; text-align: center; font-size: 1.5rem; }}
            .success {{ background: #E8F5E9; color: #2E7D32; }}
            .error {{ background: #FFEBEE; color: #C62828; }}
            .violations {{ margin: 20px 0; }}
            .word-tag {{ display: inline-block; background: #FFF3E0; color: #E65100; 
                        padding: 5px 10px; margin: 5px; border-radius: 4px; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>üá∑üá∫ –û—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ –§–ó ‚Ññ168</h1>
            <p>–°–æ–∑–¥–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="status {'success' if result.get('law_compliant') else 'error'}">
            {'‚úÖ –¢–ï–ö–°–¢ –°–û–û–¢–í–ï–¢–°–¢–í–£–ï–¢ –¢–†–ï–ë–û–í–ê–ù–ò–Ø–ú' if result.get('law_compliant') else f"‚ö†Ô∏è –ù–ê–†–£–®–ï–ù–ò–ô: {result.get('violations_count', 0)}"}
        </div>
        
        <div class="violations">
            <h2>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</h2>
            <p>–í—Å–µ–≥–æ —Å–ª–æ–≤: {result.get('total_words', 0)}</p>
            <p>–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {result.get('unique_words', 0)}</p>
            <p>–õ–∞—Ç–∏–Ω–∏—Ü–∞: {result.get('latin_count', 0)}</p>
            <p>–ê–Ω–≥–ª–∏—Ü–∏–∑–º—ã: {result.get('unknown_count', 0)}</p>
            
            {f"<h3>–°–ª–æ–≤–∞ –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü–µ:</h3>" if result.get('latin_words') else ''}
            {''.join([f'<span class="word-tag">{w}</span>' for w in result.get('latin_words', [])[:50]])}
        </div>
    </body>
    </html>
    """
    return html

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('FLASK_ENV') == 'development'
    app.run(host='0.0.0.0', port=port, debug=debug)
